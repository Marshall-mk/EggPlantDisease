{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:56:24.274938Z","iopub.status.busy":"2024-02-20T13:56:24.274599Z","iopub.status.idle":"2024-02-20T13:56:24.280542Z","shell.execute_reply":"2024-02-20T13:56:24.279844Z","shell.execute_reply.started":"2024-02-20T13:56:24.274910Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from textwrap import wrap\n","\n","import tensorflow as tf\n","from keras import layers, models\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import EfficientNetB0, DenseNet121\n","from keras.applications.densenet import DenseNet121\n","from keras.applications.vgg16 import VGG16\n","\n","from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n","    ConfusionMatrixDisplay,\n",")\n","import os"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class DataLoader():\n","    \"\"\"Data Loader class\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","    \n","    def image_equalization(self, image):\n","        \"\"\"Equalizes the histogram of an image\"\"\"\n","        # R, G, B = cv2.split(image)\n","        # output1_R = cv2.equalizeHist(R)\n","        # output1_G = cv2.equalizeHist(G)\n","        # output1_B = cv2.equalizeHist(B)\n","        # equ = cv2.merge((output1_R, output1_G, output1_B))\n","        return image\n","\n","    def load_train_data(self, path):\n","        \"\"\"Loads dataset from path\"\"\"\n","        self.train_datagen = ImageDataGenerator(\n","            rescale=1./255, \n","            validation_split=0.1,\n","            preprocessing_function=None\n","            )\n","        return self.train_datagen.flow_from_directory(\n","        path,\n","        subset='training',\n","        target_size=(224, 224),\n","        batch_size=64,\n","        color_mode=\"rgb\",\n","        class_mode='categorical')\n","        \n","    \n","    def load_val_data(self, path):\n","        \"\"\"Loads dataset from path\"\"\"\n","        self.train_datagen = ImageDataGenerator(\n","            rescale=1./255, \n","            validation_split=0.1,\n","            preprocessing_function=None)\n","        return self.train_datagen.flow_from_directory(\n","        path,\n","        subset='validation',\n","        target_size=(224, 224),\n","        batch_size=64,\n","        color_mode=\"rgb\",\n","        class_mode='categorical')\n","    \n","    \n","    def load_test_data(self, path):\n","        \"\"\"Loads dataset from path\"\"\"\n","        self.test_datagen = ImageDataGenerator(\n","            rescale=1./255,\n","            preprocessing_function=None)\n","        return self.test_datagen.flow_from_directory(\n","        path,\n","        target_size=(224, 224),\n","        batch_size=64,\n","        color_mode=\"rgb\",\n","        class_mode='categorical')\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def dense_net_model(input_shape, classes=7):\n","    \"\"\"DenseNet model\"\"\"\n","    inputs = layers.Input(shape=input_shape)\n","    base_model = DenseNet121(\n","        input_shape=input_shape, include_top=True, weights=None, classes=classes\n","    )(inputs)\n","    # base_model.trainable = False\n","    model = models.Model(inputs, base_model)\n","    return model\n","\n","\n","def vgg16_model(input_shape, classes=7):\n","    \"\"\"VGG16 model\"\"\"\n","    inputs = layers.Input(shape=input_shape)\n","    base_model = VGG16(\n","        input_shape=input_shape, include_top=True, weights=None, classes=classes\n","    )(inputs)\n","    # base_model.trainable = False\n","    model = models.Model(inputs, base_model)\n","    return model\n","\n","\n","def efficient_net_model(input_shape, classes=7):\n","    \"\"\"EfficientNet model\"\"\"\n","    inputs = layers.Input(shape=input_shape)\n","    base_model = EfficientNetB0(\n","        input_shape=input_shape, include_top=True, weights=None, classes=classes\n","    )(inputs)\n","    # base_model.trainable = False\n","    model = models.Model(inputs, base_model)\n","    return model\n","\n","\n","def compile_model(model, optimizer, loss, metrics):\n","    \"\"\"Compiles model\"\"\"\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=loss,\n","        metrics=metrics,\n","        weighted_metrics=None,\n","        run_eagerly=None,\n","        steps_per_execution=None,\n","        jit_compile=None,\n","    )\n","    return model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def main():\n","    data_loader = DataLoader()\n","    train_data = data_loader.load_train_data(\"../data/train/\")\n","    val_data = data_loader.load_val_data(\"../data/train/\")\n","    test_data = data_loader.load_test_data(\"../data/test/\")\n","    \n","    model_name = 'dense_net'\n","    \n","    if model_name == \"vgg16\":\n","        model = vgg16_model(\n","            input_shape=(224, 224, 3),\n","            classes=7,\n","        )\n","    elif model_name == \"efficient_net\":\n","        model = efficient_net_model(\n","            input_shape=(224, 224, 3),\n","            classes=7,\n","        )\n","    else:\n","        model = dense_net_model(\n","            input_shape=(224, 224, 3),\n","            classes=7,\n","        )\n","\n","    model = compile_model(\n","        model,\n","        optimizer='adamw',\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]#cfg.train.metrics,\n","    )\n","    \"\"\"Model callbacks\"\"\"\n","    earlystopping = tf.keras.callbacks.EarlyStopping(\n","        monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5\n","    )\n","    checkpointer = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f\"{model_name}.weights.h5\",\n","        save_weights_only=True,\n","        save_best_only=True,\n","    )\n","\n","    # Train the model\n","\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        validation_steps=5,\n","        epochs=25,\n","        batch_size=64,\n","        callbacks=[earlystopping, checkpointer],\n","    )\n","\n","    # Evaluate the model\n","    model.save(f\"{model_name}_model.hdf5\")\n","    test_loss, test_accuracy = model.evaluate(test_data)\n","    print(f\"Test accuracy: {test_accuracy}\")\n","\n","    # Log the confusion matrix\n","    y_pred = model.predict(test_data)\n","    y_pred = np.argmax(y_pred, axis=1)\n","    y_true = test_data.classes\n","    cm = confusion_matrix(y_true, y_pred)\n","    disp = ConfusionMatrixDisplay(\n","        confusion_matrix=cm, display_labels=test_data.class_indices\n","    )\n","    disp.plot(cmap=\"viridis\", values_format=\"d\")\n","    plt.xticks(rotation=90)\n","    plt.title(\"Confusion Matrix\")\n","    plt.savefig(\"confusion_matrix.png\")\n","\n","    # Log the classification report\n","    class_names = [k for k, v in test_data.class_indices.items()]\n","    report = classification_report(\n","        y_true, y_pred, target_names=class_names, output_dict=True\n","    )\n","    report = {k: v for k, v in report.items() if k in class_names}\n","    report = {k: {k2: round(v2, 2) for k2, v2 in v.items()} for k, v in report.items()}\n","    report = {\n","        k: dict(sorted(v.items(), key=lambda item: item[1], reverse=True))\n","        for k, v in report.items()\n","    }\n","    report = {\n","        k: {k2: v2 for k2, v2 in v.items() if k2 != \"support\"}\n","        for k, v in report.items()\n","    }\n","    report = {\n","        k: {k2: v2 for k2, v2 in v.items() if k2 != \"macro avg\"}\n","        for k, v in report.items()\n","    }\n","    report = {\n","        k: {k2: v2 for k2, v2 in v.items() if k2 != \"weighted avg\"}\n","        for k, v in report.items()\n","    }\n","    _model_history(history)\n","\n","\n","def _model_history(model_info):\n","    accuracy = model_info.history[\"accuracy\"]\n","    val_accuracy = model_info.history[\"val_accuracy\"]\n","    loss = model_info.history[\"loss\"]\n","    val_loss = model_info.history[\"val_loss\"]\n","    epochs = range(1, len(accuracy) + 1)\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(epochs, accuracy, \"g-\", label=\"Training accuracy\")\n","    plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n","    plt.title(\"Training and validation accuracy\")\n","    plt.grid()\n","    plt.savefig(\"accuracy.png\", dpi=300, bbox_inches=\"tight\")\n","\n","    plt.legend()\n","\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(epochs, loss, \"g-\", label=\"Training loss\")\n","    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n","    plt.title(\"Training and validation loss\")\n","    plt.legend()\n","    plt.grid()\n","    plt.savefig(\"loss.png\", bbox_inches=\"tight\", dpi=300)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 6048 images belonging to 7 classes.\n","Found 672 images belonging to 7 classes.\n","Found 280 images belonging to 7 classes.\n"]},{"ename":"TypeError","evalue":"'>' not supported between instances of 'NoneType' and 'int'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[9], line 43\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     36\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     38\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:133\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function\u001b[1;34m(self, force)\u001b[0m\n\u001b[0;32m    130\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m one_step_on_iterator(iterator)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m:\n\u001b[0;32m    134\u001b[0m     train_function \u001b[38;5;241m=\u001b[39m multi_step_on_iterator\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"]}],"source":["main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Define Early Stopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss', # Monitor the validation set loss\n","    patience=10,        # Number of epochs with no improvement after which training will be stopped\n","    verbose=1,          # To log the number of epoch after which training was stopped\n","    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored metric.\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import EfficientNetB0\n","\n","# Rest of your code...\n","\n","inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_COLOR))\n","outputs = EfficientNetB0(include_top=True, weights=None, classes=len(classes))(inputs)\n","efficient_net_model = tf.keras.Model(inputs, outputs)\n","\n","efficient_net_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Model Run**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use validation_data parameter to provide validation data for each epoch\n","efficient_net_hist = efficient_net_model.fit(X_train, y_train, epochs=25, validation_data=(X_val, y_val), callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["efficient_net_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["**Training and Validation Loss**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Access the training and validation loss values from the history object\n","train_loss = efficient_net_hist.history['loss']\n","val_loss = efficient_net_hist.history['val_loss']\n","\n","# Plot the training and validation loss curves with a logarithmic scale for the Y-axis\n","epochs = range(1, len(train_loss) + 1)\n","plt.plot(epochs, train_loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss (log scale)')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","save_fig(\"Eggplant_Training and Validation Loss_EfficientNET\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["**Training and Validation Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Access the training and validation accuracy values from the history object\n","train_acc = efficient_net_hist.history['accuracy']\n","val_acc = efficient_net_hist.history['val_accuracy']\n","\n","# Plot the training and validation accuracy curves\n","epochs = range(1, len(train_acc) + 1)\n","plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","save_fig(\"Eggplant_Training and Validation Accuracy_EfficientNET\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Classification Report**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","efficient_acc = efficient_net_model.evaluate(X_test, y_test)[1]\n","print('EfficientNET model accuracy:', efficient_acc*100)\n","y_pred = efficient_net_model.predict(X_test)\n","y_classes = [np.argmax(element) for element in y_pred]\n","\n","# Convert one-hot encoded true labels to labels\n","y_true_labels = np.argmax(y_test, axis=1)\n","\n","# Generate classification report\n","class_report = classification_report(y_true_labels, y_classes, target_names=['Wilt Disease', 'Small Leaf Disease', 'Healthy Leaf', 'Insect Pest Disease', 'Mosaic Virus Disease', 'Leaf Spot Disease','White Mold Disease'])\n","print(class_report)"]},{"cell_type":"markdown","metadata":{},"source":["**Test Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["efficient_acc = efficient_net_model.evaluate(X_test, y_test)[1]\n","print('EfficientNET TEST accuracy:', efficient_acc*100)"]},{"cell_type":"markdown","metadata":{},"source":["**Confusion Matrix**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","# Evaluate the model on the test set and get predictions\n","y_pred = efficient_net_model.predict(X_test)\n","y_pred_labels = np.argmax(y_pred, axis=1)  # Convert one-hot encoded predictions to labels\n","\n","# Convert one-hot encoded true labels to labels\n","y_true_labels = np.argmax(y_test, axis=1)\n","\n","# Generate confusion matrix\n","cm = confusion_matrix(y_true_labels, y_pred_labels)\n","\n","# Display the confusion matrix\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Wilt Disease', 'Small Leaf Disease', 'Healthy Leaf', 'Insect Pest Disease', 'Mosaic Virus Disease', 'Leaf Spot Disease','White Mold Disease'])\n","disp.plot(cmap='viridis', values_format='d')\n","plt.xticks(rotation=90)\n","plt.title('Confusion Matrix')\n","save_fig(\"CM_EfficientNET\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["**Predicting Images**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_fig(\"Result_EfficientNET\")\n","show_images(images=X_test, actual_classes=y_test, predicted_classes=y_classes, test_nums=[1, 40, 100, 70]) # Test Cases: 1, 40, 100, 70"]},{"cell_type":"markdown","metadata":{},"source":["# VGG"]},{"cell_type":"markdown","metadata":{},"source":["**Early Stopping**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Define Early Stopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss', # Monitor the validation set loss\n","    patience=10,        # Number of epochs with no improvement after which training will be stopped\n","    verbose=1,          # To log the number of epoch after which training was stopped\n","    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored metric.\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["**Model Code**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_COLOR))\n","outputs = VGG16(include_top=True, weights=None, classes=len(classes))(inputs)\n","vgg_model = tf.keras.Model(inputs, outputs)\n","\n","vgg_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] )"]},{"cell_type":"markdown","metadata":{},"source":["**Model Run**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vgg_hist = vgg_model.fit(X_train, y_train, epochs=25, validation_data=(X_val, y_val), callbacks=[early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["**Model Summary**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vgg_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["**Training and Validation Loss**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Access the training and validation loss values from the history object\n","train_loss = vgg_hist.history['loss']\n","val_loss = vgg_hist.history['val_loss']\n","\n","# Plot the training and validation loss curves with a logarithmic scale for the Y-axis\n","epochs = range(1, len(train_loss) + 1)\n","plt.plot(epochs, train_loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss (log scale)')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","save_fig(\"Eggplant_Training and Validation Loss_VGG\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["**Training and Validation Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Access the training and validation accuracy values from the history object\n","train_acc = vgg_hist.history['accuracy']\n","val_acc = vgg_hist.history['val_accuracy']\n","\n","# Plot the training and validation accuracy curves\n","epochs = range(1, len(train_acc) + 1)\n","plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","save_fig(\"Eggplant_Training and Validation Accuracy_VGG\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Classification Report**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","vgg_acc = vgg_model.evaluate(X_test, y_test)[1]\n","print('VGG model accuracy:', vgg_acc*100)\n","y_pred = efficient_net_model.predict(X_test)\n","y_classes = [np.argmax(element) for element in y_pred]\n","\n","# Convert one-hot encoded true labels to labels\n","y_true_labels = np.argmax(y_test, axis=1)\n","\n","# Generate classification report\n","class_report = classification_report(y_true_labels, y_classes, target_names=['Wilt Disease', 'Small Leaf Disease', 'Healthy Leaf', 'Insect Pest Disease', 'Mosaic Virus Disease', 'Leaf Spot Disease','White Mold Disease'])\n","print(class_report)"]},{"cell_type":"markdown","metadata":{},"source":["**Test Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vgg_acc = vgg_model.evaluate(X_test, y_test)[1]\n","print('VGG TEST accuracy:', vgg_acc*100)"]},{"cell_type":"markdown","metadata":{},"source":["**Confusion Matrix**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","# Evaluate the model on the test set and get predictions\n","y_pred = vgg_model.predict(X_test)\n","y_pred_labels = np.argmax(y_pred, axis=1)  # Convert one-hot encoded predictions to labels\n","\n","# Convert one-hot encoded true labels to labels\n","y_true_labels = np.argmax(y_test, axis=1)\n","\n","# Generate confusion matrix\n","cm = confusion_matrix(y_true_labels, y_pred_labels)\n","\n","# Display the confusion matrix\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Wilt Disease', 'Small Leaf Disease', 'Healthy Leaf', 'Insect Pest Disease', 'Mosaic Virus Disease', 'Leaf Spot Disease','White Mold Disease'])\n","disp.plot(cmap='viridis', values_format='d')\n","plt.xticks(rotation=90)\n","plt.title('Confusion Matrix')\n","save_fig(\"CM_VGG\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["**Predicting Images**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_fig(\"Result_VGGNET\")\n","show_images(images=X_test, actual_classes=y_test, predicted_classes=y_classes, test_nums=[1, 40, 100, 70]) # Test Cases: 1, 40, 100, 70"]},{"cell_type":"markdown","metadata":{},"source":["# Vision Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X, y = data_preparation(DATASET_DIR, classes)\n","EQU_IMAGES = image_equalization(ALL_IMAGES)\n","print('Number of images: ', len(ALL_IMAGES))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EQU_IMAGES = np.array(EQU_IMAGES)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(EQU_IMAGES, y, test_size=0.22, random_state=42)\n","print(f\"x_train shape: {X_train.shape} - y_train shape: {y_train.shape}\")\n","print(f\"x_test shape: {X_test.shape} - y_test shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_COLOR)\n","num_classes = 7\n","learning_rate = 0.001\n","weight_decay = 0.0001\n","batch_size = 256\n","num_epochs = 120\n","image_size = 72 # image resized to 72, 72\n","patch_size = 6\n","num_patches = (image_size // patch_size) ** 2\n","\n","projection_dim = 4 # dimension vectors\n","num_heads = 4\n","transformer_units = [projection_dim * 2, projection_dim,]\n","transformer_layers = 8\n","mlp_head_units = [2048, 1024]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_augmentation = keras.Sequential([\n","    layers.experimental.preprocessing.Normalization(),\n","    layers.experimental.preprocessing.Resizing(image_size, image_size),\n","    layers.experimental.preprocessing.RandomFlip('horizontal'),\n","    layers.experimental.preprocessing.RandomRotation(factor=0.02),\n","    layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n","\n","],\n","    name='layers'\n",")\n","\n","data_augmentation.layers[0].adapt(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(4, 4))\n","image = X_train[np.random.choice(range(X_train.shape[0]))]\n","plt.imshow(image.astype(\"uint8\"))\n","plt.axis(\"off\")\n","\n","resized_image = tf.image.resize(\n","    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",")\n","patches = Patches(patch_size)(resized_image)\n","print(f\"Image size: {image_size} X {image_size}\")\n","print(f\"Patch size: {patch_size} X {patch_size}\")\n","print(f\"Patches per image: {patches.shape[1]}\")\n","print(f\"Elements per patch: {patches.shape[-1]}\")\n","\n","n = int(np.sqrt(patches.shape[1]))\n","plt.figure(figsize=(4, 4))\n","for i, patch in enumerate(patches[0]):\n","    ax = plt.subplot(n, n, i + 1)\n","    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n","    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    augmented = data_augmentation(inputs)\n","    # Create patches.\n","    patches = Patches(patch_size)(augmented)\n","    # Encode patches.\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # Create a multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Create a [batch_size, projection_dim] tensor.\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","    # Classify outputs.\n","    logits = layers.Dense(num_classes)(features)\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=logits)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def run_experiment(model):\n","    optimizer = tfa.optimizers.AdamW(\n","        learning_rate=learning_rate, weight_decay=weight_decay\n","    )\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","        metrics=[\n","            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","        ],\n","    )\n","\n","    checkpoint_filepath = \"/tmp/checkpoint\"\n","    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","        checkpoint_filepath,\n","        monitor=\"val_accuracy\",\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","\n","    history = model.fit(\n","        x=X_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=num_epochs,\n","        validation_split=0.1,\n","        callbacks=[checkpoint_callback],\n","    )\n","\n","    model.load_weights(checkpoint_filepath)\n","    _, accuracy = model.evaluate(X_test, y_test)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","    return history, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def run_experiment(model):\n","    optimizer = tfa.optimizers.AdamW(\n","        learning_rate=learning_rate, weight_decay=weight_decay\n","    )\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","        metrics=[\n","            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","        ],\n","    )\n","\n","    checkpoint_filepath = \"/tmp/checkpoint\"\n","    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","        checkpoint_filepath,\n","        monitor=\"val_accuracy\",\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","\n","    history = model.fit(\n","        x=X_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=num_epochs,\n","        validation_split=0.1,\n","        callbacks=[checkpoint_callback],\n","    )\n","\n","    model.load_weights(checkpoint_filepath)\n","    y_pred = np.argmax(model.predict(X_test), axis=-1)\n","    report = classification_report(y_test, y_pred)\n","\n","    _, accuracy = model.evaluate(X_test, y_test)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","    print(\"Classification Report:\")\n","    print(report)\n","\n","    return history, accuracy, report\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vit_classifier = create_vit_classifier()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history, vit_accuracy = run_experiment(vit_classifier)"]},{"cell_type":"markdown","metadata":{},"source":["# Swin Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ALL_IMAGES, LABELS = data_preparation(DATASET_DIR, classes)\n","EQU_IMAGES = image_equalization(ALL_IMAGES)\n","print('Number of images: ', len(ALL_IMAGES))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["onehot_encoded = hot_encoder(LABELS)\n","X, y = EQU_IMAGES, onehot_encoded"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.22, random_state=42)\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_COLOR)\n","num_classes = 7\n","patch_size = (2, 2)  # 2-by-2 sized patches\n","dropout_rate = 0.03  # Dropout rate\n","num_heads = 8  # Attention heads\n","embed_dim = 64  # Embedding dimension\n","num_mlp = 256  # MLP layer size\n","qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n","window_size = 2  # Size of attention window\n","shift_size = 1  # Size of shifting window\n","image_dimension = input_shape[0]  # Initial image size\n","\n","num_patch_x = input_shape[0] // patch_size[0]\n","num_patch_y = input_shape[1] // patch_size[1]\n","\n","learning_rate = 1e-3\n","batch_size = 32\n","num_epochs = 40\n","validation_split = 0.1\n","weight_decay = 0.0001\n","label_smoothing = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def window_partition(x, window_size):\n","    _, height, width, channels = x.shape\n","    patch_num_y = height // window_size\n","    patch_num_x = width // window_size\n","    x = tf.reshape(\n","        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n","    )\n","    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n","    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n","    return windows\n","\n","\n","def window_reverse(windows, window_size, height, width, channels):\n","    patch_num_y = height // window_size\n","    patch_num_x = width // window_size\n","    x = tf.reshape(\n","        windows,\n","        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n","    )\n","    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n","    x = tf.reshape(x, shape=(-1, height, width, channels))\n","    return x\n","\n","\n","class DropPath(layers.Layer):\n","    def __init__(self, drop_prob=None, **kwargs):\n","        super(DropPath, self).__init__(**kwargs)\n","        self.drop_prob = drop_prob\n","\n","    def call(self, x):\n","        input_shape = tf.shape(x)\n","        batch_size = input_shape[0]\n","        rank = x.shape.rank\n","        shape = (batch_size,) + (1,) * (rank - 1)\n","        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n","        path_mask = tf.floor(random_tensor)\n","        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class WindowAttention(layers.Layer):\n","    def __init__(\n","        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n","    ):\n","        super(WindowAttention, self).__init__(**kwargs)\n","        self.dim = dim\n","        self.window_size = window_size\n","        self.num_heads = num_heads\n","        self.scale = (dim // num_heads) ** -0.5\n","        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n","        self.dropout = layers.Dropout(dropout_rate)\n","        self.proj = layers.Dense(dim)\n","\n","    def build(self, input_shape):\n","        num_window_elements = (2 * self.window_size[0] - 1) * (\n","            2 * self.window_size[1] - 1\n","        )\n","        self.relative_position_bias_table = self.add_weight(\n","            shape=(num_window_elements, self.num_heads),\n","            initializer=tf.initializers.Zeros(),\n","            trainable=True,\n","        )\n","        coords_h = np.arange(self.window_size[0])\n","        coords_w = np.arange(self.window_size[1])\n","        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n","        coords = np.stack(coords_matrix)\n","        coords_flatten = coords.reshape(2, -1)\n","        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n","        relative_coords = relative_coords.transpose([1, 2, 0])\n","        relative_coords[:, :, 0] += self.window_size[0] - 1\n","        relative_coords[:, :, 1] += self.window_size[1] - 1\n","        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n","        relative_position_index = relative_coords.sum(-1)\n","\n","        self.relative_position_index = tf.Variable(\n","            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n","        )\n","\n","    def call(self, x, mask=None):\n","        _, size, channels = x.shape\n","        head_dim = channels // self.num_heads\n","        x_qkv = self.qkv(x)\n","        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n","        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n","        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n","        q = q * self.scale\n","        k = tf.transpose(k, perm=(0, 1, 3, 2))\n","        attn = q @ k\n","\n","        num_window_elements = self.window_size[0] * self.window_size[1]\n","        relative_position_index_flat = tf.reshape(\n","            self.relative_position_index, shape=(-1,)\n","        )\n","        relative_position_bias = tf.gather(\n","            self.relative_position_bias_table, relative_position_index_flat\n","        )\n","        relative_position_bias = tf.reshape(\n","            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n","        )\n","        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n","        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n","\n","        if mask is not None:\n","            nW = mask.get_shape()[0]\n","            mask_float = tf.cast(\n","                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n","            )\n","            attn = (\n","                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n","                + mask_float\n","            )\n","            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n","            attn = keras.activations.softmax(attn, axis=-1)\n","        else:\n","            attn = keras.activations.softmax(attn, axis=-1)\n","        attn = self.dropout(attn)\n","\n","        x_qkv = attn @ v\n","        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n","        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n","        x_qkv = self.proj(x_qkv)\n","        x_qkv = self.dropout(x_qkv)\n","        return x_qkv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class SwinTransformer(layers.Layer):\n","    def __init__(\n","        self,\n","        dim,\n","        num_patch,\n","        num_heads,\n","        window_size=7,\n","        shift_size=0,\n","        num_mlp=1024,\n","        qkv_bias=True,\n","        dropout_rate=0.0,\n","        **kwargs,\n","    ):\n","        super(SwinTransformer, self).__init__(**kwargs)\n","\n","        self.dim = dim  # number of input dimensions\n","        self.num_patch = num_patch  # number of embedded patches\n","        self.num_heads = num_heads  # number of attention heads\n","        self.window_size = window_size  # size of window\n","        self.shift_size = shift_size  # size of window shift\n","        self.num_mlp = num_mlp  # number of MLP nodes\n","\n","        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n","        self.attn = WindowAttention(\n","            dim,\n","            window_size=(self.window_size, self.window_size),\n","            num_heads=num_heads,\n","            qkv_bias=qkv_bias,\n","            dropout_rate=dropout_rate,\n","        )\n","        self.drop_path = DropPath(dropout_rate)\n","        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n","\n","        self.mlp = keras.Sequential(\n","            [\n","                layers.Dense(num_mlp),\n","                layers.Activation(keras.activations.gelu),\n","                layers.Dropout(dropout_rate),\n","                layers.Dense(dim),\n","                layers.Dropout(dropout_rate),\n","            ]\n","        )\n","\n","        if min(self.num_patch) < self.window_size:\n","            self.shift_size = 0\n","            self.window_size = min(self.num_patch)\n","\n","    def build(self, input_shape):\n","        if self.shift_size == 0:\n","            self.attn_mask = None\n","        else:\n","            height, width = self.num_patch\n","            h_slices = (\n","                slice(0, -self.window_size),\n","                slice(-self.window_size, -self.shift_size),\n","                slice(-self.shift_size, None),\n","            )\n","            w_slices = (\n","                slice(0, -self.window_size),\n","                slice(-self.window_size, -self.shift_size),\n","                slice(-self.shift_size, None),\n","            )\n","            mask_array = np.zeros((1, height, width, 1))\n","            count = 0\n","            for h in h_slices:\n","                for w in w_slices:\n","                    mask_array[:, h, w, :] = count\n","                    count += 1\n","            mask_array = tf.convert_to_tensor(mask_array)\n","\n","            # mask array to windows\n","            mask_windows = window_partition(mask_array, self.window_size)\n","            mask_windows = tf.reshape(\n","                mask_windows, shape=[-1, self.window_size * self.window_size]\n","            )\n","            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n","                mask_windows, axis=2\n","            )\n","            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n","            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n","            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n","\n","    def call(self, x):\n","        height, width = self.num_patch\n","        _, num_patches_before, channels = x.shape\n","        x_skip = x\n","        x = self.norm1(x)\n","        x = tf.reshape(x, shape=(-1, height, width, channels))\n","        if self.shift_size > 0:\n","            shifted_x = tf.roll(\n","                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n","            )\n","        else:\n","            shifted_x = x\n","\n","        x_windows = window_partition(shifted_x, self.window_size)\n","        x_windows = tf.reshape(\n","            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n","        )\n","        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n","\n","        attn_windows = tf.reshape(\n","            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n","        )\n","        shifted_x = window_reverse(\n","            attn_windows, self.window_size, height, width, channels\n","        )\n","        if self.shift_size > 0:\n","            x = tf.roll(\n","                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n","            )\n","        else:\n","            x = shifted_x\n","\n","        x = tf.reshape(x, shape=(-1, height * width, channels))\n","        x = self.drop_path(x)\n","        x = x_skip + x\n","        x_skip = x\n","        x = self.norm2(x)\n","        x = self.mlp(x)\n","        x = self.drop_path(x)\n","        x = x_skip + x\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PatchExtract(layers.Layer):\n","    def __init__(self, patch_size, **kwargs):\n","        super(PatchExtract, self).__init__(**kwargs)\n","        self.patch_size_x = patch_size[0]\n","        self.patch_size_y = patch_size[0]\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n","            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n","            rates=(1, 1, 1, 1),\n","            padding=\"VALID\",\n","        )\n","        patch_dim = patches.shape[-1]\n","        patch_num = patches.shape[1]\n","        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PatchEmbedding(layers.Layer):\n","    def __init__(self, num_patch, embed_dim, **kwargs):\n","        super(PatchEmbedding, self).__init__(**kwargs)\n","        self.num_patch = num_patch\n","        self.proj = layers.Dense(embed_dim)\n","        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n","\n","    def call(self, patch):\n","        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n","        return self.proj(patch) + self.pos_embed(pos)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PatchMerging(tf.keras.layers.Layer):\n","    def __init__(self, num_patch, embed_dim):\n","        super(PatchMerging, self).__init__()\n","        self.num_patch = num_patch\n","        self.embed_dim = embed_dim\n","        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n","\n","    def call(self, x):\n","        height, width = self.num_patch\n","        _, _, C = x.get_shape().as_list()\n","        x = tf.reshape(x, shape=(-1, height, width, C))\n","        x0 = x[:, 0::2, 0::2, :]\n","        x1 = x[:, 1::2, 0::2, :]\n","        x2 = x[:, 0::2, 1::2, :]\n","        x3 = x[:, 1::2, 1::2, :]\n","        x = tf.concat((x0, x1, x2, x3), axis=-1)\n","        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n","        return self.linear_trans(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = layers.Input(input_shape)\n","x = layers.RandomCrop(image_dimension, image_dimension)(input)\n","x = layers.RandomFlip(\"horizontal\")(x)\n","x = PatchExtract(patch_size)(x)\n","x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n","x = SwinTransformer(\n","    dim=embed_dim,\n","    num_patch=(num_patch_x, num_patch_y),\n","    num_heads=num_heads,\n","    window_size=window_size,\n","    shift_size=0,\n","    num_mlp=num_mlp,\n","    qkv_bias=qkv_bias,\n","    dropout_rate=dropout_rate,\n",")(x)\n","x = SwinTransformer(\n","    dim=embed_dim,\n","    num_patch=(num_patch_x, num_patch_y),\n","    num_heads=num_heads,\n","    window_size=window_size,\n","    shift_size=shift_size,\n","    num_mlp=num_mlp,\n","    qkv_bias=qkv_bias,\n","    dropout_rate=dropout_rate,\n",")(x)\n","x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n","x = layers.GlobalAveragePooling1D()(x)\n","output = layers.Dense(num_classes, activation=\"softmax\")(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = keras.Model(input, output)\n","model.compile(\n","    loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n","    optimizer=tfa.optimizers.AdamW(\n","        learning_rate=learning_rate, weight_decay=weight_decay\n","    ),\n","    metrics=[\n","        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n","    ],\n",")\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    batch_size=batch_size,\n","    epochs=num_epochs,\n","    validation_split=validation_split,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss, swin_accuracy= model.evaluate(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["swin_accuracy"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4152384,"sourceId":7183441,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
